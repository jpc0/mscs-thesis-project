\section{Details of the Experiments}
\label{sec:experiments}

To explore these hypotheses a range of experiments were performed in the three chosen languages (C, C++, Rust), with the programs being run under a ``harness'' application that measures various memory, performance, and energy metrics. Additional tools were used to examine the running programs for memory leaks, as well as measure aspects of the source code itself.

\subsection{Definitions and Measurements}

To begin, some concepts and terms will be defined.

\subsubsection{RAPL (Running Average Power Limit)}

The \textit{Running Average Power Limit} (RAPL) measurement system was introduced by Intel into their CPU products starting with the Sandybridge family of processors. The system allows measuring energy over several areas:

\begin{description}
\item[Package] The full (socketed) processor package, which may contain multiple cores.
\item[Power-Plane 0] The domain that encompasses the combined cores within the package.
\item[Power-Plane 1] Referred to as the ``uncore'', this domain generally covers the integrated GPU (if present).
\item[DRAM] The domain for the system's DRAM, whose energy usage is separate from the package.
\item[Psys] The domain that covers the entire system-on-chip energy usage. This would include the package and DRAM values, as well as other system-level energy consumption.
\end{description}

A computer system may have more than one package, and the RAPL interface includes methods for determining the number of packages and gathering the energy readings for each package separately. It is not possible to measure a package's energy usage at the level of an individual core.

\subsubsection{SLOC (Source Lines Of Code)}

The SLOC, or \textit{Source Lines Of Code}, measurement attempts to evaluate the conciseness of the source code to a program. It generally distinguishes between physically lines of text, comments, and actual source lines.

\subsubsection{Metrics}

For each program comprising an experiment, the following data was gathered either dynamically (from executions of the program) or statically (through non-execution analysis of the programs' source code).

\begin{description}
\item[Total Program Run-time] The complete run-time of the program, as measured by the harness program. Unlike the next metric, this will include program initialization time, the input/output operations of loading the data to be processed, etc. Measured in floating-point seconds.
\item[Algorithm Run-Time] The time spent within running the algorithm itself over the complete set of test data. This is measured solely on the processing of data, and does not include I/O, set-up of the environment, or post-algorithm steps such as freeing of memory. Also measured in floating-point seconds.
\item[Maximum Memory Usage] The largest amount of memory allocated for the running program throughout the course of its execution, in megabytes. This represents the largest size to which the program grew during the run.
\item[Power-Plane 0 (CPU) Energy Usage] The energy consumed by the CPU cores during the execution of the program. Measured over the full lifespan of the program, not just the algorithm itself. Measured in Joules.
\item[DRAM Energy Usage] The energy consumed by the DRAM during the full lifespan of the program. Measured in Joules.
\item[Full Package Energy Usage] The energy consumed by the full (socketed) package, which includes the CPU cores' energy but not the DRAM energy. Measured in Joules.
\item[Source Lines Of Code] The measured lines of code in the implementation of the program, using a tool\footnote{sloc: \texttt{https://github.com/flosse/sloc}} designed to measure this using consistent standards across different programming languages.
\end{description}

The Power-Plane 1 (GPU) RAPL values were excluded because the testing machine's package did not have an integrated GPU. Additionally, the Psys values were excluded because they deemed unnecessary in the context of having the package, CPU and DRAM values.

\subsection{Languages Under Consideration}

As mentioned above, the experiments were performed on three languages. The languages were chosen for their commonalities as well as their differences:

\begin{itemize}
\item Each language is compiled to machine code (none are interpreted or make use of virtual machines)
\item Each is widely regarded within their respective communities as being viable for systems-level programming
\item Each takes a somewhat different view on memory management
\end{itemize}

\subsubsection{C}

The C programming language is the oldest and most-established of the three languages. Originally designed in the early 1970's by Dennis Ritchie, it remains a very widely-used and influential language since its first appearance in 1972. Since 1989, it has been standardized by both ANSI (the American National Standards Institute) and by the International Organization for Standardization (ISO).

\subsubsection{C++}

C++ was developed initially as an extension of C, by Bjarne Stroustrup while working at AT\&T Bell Labs. It first appeared in 1985 and was initially standardized in 1998. Initially envisioned as ``C with Classes'', the language has been significantly expanded over the years to include many more features while still maintaining low-level memory accessibility. C++ attempts to offer more expressive, concise coding than C, with many of C's memory-management concerns dealt with automatically by class constructors and destructors.

\subsubsection{Rust}

Rust is the newest of the three languages, having first appeared in 2010 (as covered in detail in section \ref{sec:rust}). Rust brings a promise of expressiveness equal to or greater than C++, with greater safety in the areas of memory management and ownership.

\subsection{Selected Algorithms}

Here, the various algorithms that were chosen will be covered in detail.

\subsubsection{Knuth, Morris, and Pratt}

\subsubsection{Boyer and Moore}

\subsubsection{Shift-Or}

\subsubsection{Aho and Corasick}

\subsubsection{Other Algorithms Considered}

\subsection{Degrees of Optimization}

\subsection{Data Used}

\subsubsection{Method of Generation}

\subsubsection{Nature of the Data Used}

\subsection{Testing Platform}

The experiments were run on a dedicated machine running a version of the Linux operating system. The set of installed software was kept minimized to reduce the interference with general energy usage during the runs of experiments.

\subsubsection{Hardware Specifications}

The machine used for the experiments is an Intel-brand NUC7i5BNH i5-7260U, an ultra-compact device referred to by Intel as a ``Next Unit of Computing'' (NUC). The machine features the following specifications:

\begin{table}[h!]
\begin{center}
\begin{tabular}{|ll|}
\hline
Processor & Intel® Core™ i5-7260U Processor\\
Processor Base Frequency & 2.20 GHz\\
Max Turbo Frequency & 3.40 GHz\\
Memory Type & DDR4-2133 1.2V SO-DIMM\\
Installed Memory & 8 GB\\
Internal Drive Form Factor & M.2 and 2.5''\\
Installed Storage & 120 GB M.2 SSD\\
\hline
\end{tabular}
\caption{Hardware specifications of the test platform}
\end{center}
\label{table:hardware_specs}
\end{table}

The CPU is dual-core, with hyperthreading cores, for a total of 4 computational cores. This did not come into play for the experiments, as none of the code was written as multi-threaded.

\subsubsection{Operating System and Configuration}

The NUC was cleaned of the vendor-installed operating system. Linux was installed on it using the minimal server edition of Ubuntu Linux 22.04.1. All unnecessary packages and software services were either disabled or removed completely.

The necessary development software (see next section) was then installed. This included the Linux version of the ``Homebrew''\footnote{Homebrew: \texttt{https://brew.sh/}} package manager. Homebrew was specifically used to install the latest version of the LLVM Compiler Infrastructure, to allow all experiment code to be compiled directly on the NUC (rather than copying executable files from a different machine). Core software development packages from Ubuntu were also installed at this time.

\subsubsection{Compilers and Other Tools}

The following table lists the primary software tools and packages that were used in the creation and execution of the experiments, with the source from which they were obtained. The double line after the LLVM details indicates that the remaining tools were used on the development machine only, not on the NUC. These tools were used in the testing and evaluation of the experiments code prior to running experiments on the NUC.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|l|r|l|}
\hline
Tool & Version & Source\\
\hline
GNU Make & 4.3 & Ubuntu 22.04\\
GCC & 11.2.0 & Ubuntu 22.04\\
LLVM & 15.0.1 & Linux Homebrew\\
\hline
\hline
Python & 3.10.6 & Ubuntu 22.04\\
Valgrind & 3.19.0 & Linux Homebrew\\
\texttt{sloc} & 0.2.1 & Linux Homebrew\\
\texttt{perf} & 5.15.53 & Ubuntu 22.04\\
\hline
\end{tabular}
\caption{List of software tools used}
\end{center}
\label{table:tools}
\end{table}

The Valgrind\footnote{Valgrind: \texttt{https://valgrind.org/}} tool was used to identify memory leaks in each of the experiment programs, while \texttt{sloc} was used to measure the Source Lines Of Code metric as part of determining the conciseness and expressiveness of the programs. The \texttt{perl} tool was used to identify performance bottlenecks in the running programs. Lastly, the Python programming language was used to develop the tools which were then used to process and analyze the data gathered during the running of the experiments. It was also used to generate the randomized data that the experiments used to exercise the algorithms.